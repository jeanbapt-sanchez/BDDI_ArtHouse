<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Souffle</title>
  </head>
  <body>
    <h1>Yoooo, souffle sur ton tel pour voir</h1>
    <p>coucou 3</p>
    <p>coucou</p>
    <button class="start">Start mic</button>

    <div
      class="circle"
      style="
        height: 40px;
        width: 40px;
        background: red;
        border-radius: 50px;
        z-index: 1000;
      "
    ></div>
    <div
      style="
        width: 100%;
        height: 100%;
        display: flex;
        justify-content: flex-end;
      "
    >
      <button class="stop">stop mic</button>
    </div>
    <script>
      let audioCtx;
      let circle = document.querySelector(".circle");
      let start = document.querySelector(".start");
      let stopMic = document.querySelector(".stop");
      navigator.getUserMedia =
        navigator.getUserMedia ||
        navigator.mediaDevices.getUserMedia ||
        navigator.webkitGetUserMedia ||
        navigator.mozGetUserMedia ||
        navigator.msGetUserMedia;

      let progressionAudioAnim = 0;
      let audioStream;

      function visualize(stream) {
        if (!audioCtx) {
          const myAudioContext =
            window.AudioContext || window.webkitAudioContext;
          audioCtx = new myAudioContext();
        }

        const source = audioCtx.createMediaStreamSource(stream);

        const analyser = audioCtx.createAnalyser();
        analyser.fftSize = 2048;
        const bufferLength = analyser.frequencyBinCount;
        const dataArray = new Uint8Array(bufferLength);

        source.connect(analyser);
        function update() {
          requestAnimationFrame(update);

          analyser.getByteTimeDomainData(dataArray);

          if (dataArray[1] > 160) {
            progressionAudioAnim++;
          }

          console.log("prog", progressionAudioAnim);

          circle.style.transform = `scale(${dataArray[1] / 8})`;
        }
        if ((progressionAudioAnim = 0)) {
          stream
            .getTracks() // get all tracks from the MediaStream
            .forEach((track) => track.stop());
        }
        update();
        //analyser.connect(audioCtx.destination);
      }

      start.addEventListener("click", () => {
        if (navigator.mediaDevices.getUserMedia) {
          console.log("getUserMedia supported");

          const constraints = { audio: true };
          let chunks = [];

          let onSuccess = stream => {
            // mediaRecorder = new MediaRecorder(stream);
            audioStream = stream.getAudioTracks().length && stream.getAudioTracks()[0];
            console.log(stream)
            visualize(stream);
          };

          let onError = () => {
            console.log("The following error occured: " + err);
          };
          navigator.mediaDevices
            .getUserMedia(constraints)
            .then(onSuccess, onError);
        }
      });
      stopMic.addEventListener("click", () => {
        audioStream.stop()
        console.log('stop')
      });
    </script>
  </body>
</html>
